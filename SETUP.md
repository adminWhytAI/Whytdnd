# WhytDD - Guide de Setup

## âœ… Ã‰tat Actuel du Setup

### ComplÃ©tÃ©
- âœ… Arborescence backend crÃ©Ã©e
- âœ… Structure models/ crÃ©Ã©e
- âœ… TinyLlama dÃ©placÃ© dans models/gguf/
- âœ… Configuration (config.py, logger.py, exceptions.py)
- âœ… .gitignore crÃ©Ã©
- âœ… requirements.txt mis Ã  jour
- âœ… Installation dÃ©pendances Python en cours

### En Attente
- â³ TÃ©lÃ©chargement Mistral-7B-Instruct
- â³ Setup frontend (React + Vite)
- â³ Documentation immersive

## ğŸš€ Prochaines Ã‰tapes

### 1. VÃ©rifier Installation DÃ©pendances

Attendre que l'installation se termine, puis vÃ©rifier :

```bash
python backend/utils/config.py
```

Devrait afficher la configuration et vÃ©rifier que tout est OK.

### 2. TÃ©lÃ©charger Mistral 7B (RecommandÃ©)

**Option A : TÃ©lÃ©chargement Manuel**
1. Aller sur https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF
2. TÃ©lÃ©charger `mistral-7b-instruct-v0.2.Q4_K_M.gguf` (4.37 GB)
3. Placer dans `models/gguf/`

**Option B : Via Script Python**

```bash
python backend/scripts/download_mistral.py
```

### 3. Tester le ModÃ¨le

```bash
python backend/scripts/test_model.py
```

### 4. CrÃ©er Documentation Immersive (Phase 1)

CrÃ©er les fichiers dans `Documentation/Immersive/` :
- Races/ : Being_A_Dwarf_Mountain.md, etc.
- Classes/ : Being_A_Fighter.md, etc.
- Stats/ : Having_High_Strength.md, etc.
- Alignments/ : Living_Lawful_Good.md, etc.

Voir TODO.md Phase 1 pour la liste complÃ¨te.

## ğŸ“‚ Structure Actuelle

```
WhytDD/
â”œâ”€â”€ backend/              âœ… CrÃ©Ã©
â”‚   â”œâ”€â”€ knowledge_parser/
â”‚   â”œâ”€â”€ character_creator/
â”‚   â”œâ”€â”€ rag_engine/
â”‚   â”œâ”€â”€ llm_interface/
â”‚   â”œâ”€â”€ api/
â”‚   â””â”€â”€ utils/            âœ… Config crÃ©Ã©e
â”‚
â”œâ”€â”€ models/               âœ… CrÃ©Ã©
â”‚   â”œâ”€â”€ gguf/
â”‚   â”‚   â””â”€â”€ tinyllama-1.1b-chat-q4_k_m.gguf  âœ…
â”‚   â””â”€â”€ config/
â”‚       â””â”€â”€ model_config.json  âœ…
â”‚
â”œâ”€â”€ Documentation/        âœ… Existe
â”‚   â”œâ”€â”€ Technical/        âœ… Guides D&D
â”‚   â””â”€â”€ Immersive/        âœ… Structure crÃ©Ã©e
â”‚
â””â”€â”€ data/                 âœ… CrÃ©Ã©
    â”œâ”€â”€ chromadb/
    â””â”€â”€ characters/
```

## âš™ï¸ Configuration Actuelle

**ModÃ¨le Production** : Mistral-7B-Instruct-v0.2 (Ã  tÃ©lÃ©charger)
**ModÃ¨le Dev** : TinyLlama-1.1B (dÃ©jÃ  prÃ©sent)

Pour basculer entre les deux, Ã©diter `models/config/model_config.json` :
- Mistral 7B : Meilleure qualitÃ©, plus lent
- TinyLlama : Rapide, qualitÃ© limitÃ©e

## ğŸ› RÃ©solution ProblÃ¨mes

### Erreur "ModÃ¨le non trouvÃ©"
â†’ TÃ©lÃ©charger Mistral 7B ou utiliser TinyLlama temporairement

### Erreur "ChromaDB"
â†’ Installation en cours, patienter

### Erreur "llama-cpp-python"
â†’ Installation en cours, si Ã©chec :
```bash
pip install llama-cpp-python --force-reinstall
```

## ğŸ“ Notes

- Les modÃ¨les GGUF sont dans .gitignore (trop gros)
- TinyLlama OK pour dev, Mistral 7B pour prod
- Context Mistral : 8192 tokens vs TinyLlama : 2048 tokens

---

**Voir TODO.md pour la roadmap complÃ¨te** ğŸ¯
